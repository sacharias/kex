\documentclass{kththesis}
\usepackage{csquotes} % Recommended by biblatex
\usepackage[style=numeric,sorting=none,backend=biber]{biblatex}
\usepackage[swedish]{babel}
\usepackage{graphicx}
\graphicspath{ {../images/} }

\addbibresource{references.bib} % The file containing our references, in BibTeX format

\title{Find objects in real estate images with convolutional neural networks}
\alttitle{Hitta object i fastighetsbilder med convolutional neural networks}
\author{Oskar Råhlén och Sacharias Sjöqvist}
\email{orahlen@kth.se och sacsjo@kth.se}
\supervisor{Handledare}
\examiner{Examinator}
\programme{Degree project in Computer Science}
\school{School of Electrical Engineering and Computer Science}
\date{\today}

% Uncomment the next line to include cover generated at https://intra.kth.se/kth-cover?l=en
% \kthcover{kth-cover.pdf}

\begin{document}
% Frontmatter includes the title-page, abstracts and table-of-contents
\frontmatter

\titlepage

\begin{abstract}
  English abstract goes here.
\end{abstract}

\begin{otherlanguage}{swedish}
  \begin{abstract}
    Svenskt sammanfattning
  \end{abstract}
\end{otherlanguage}

\tableofcontents

% Mainmatter is where the actual contents of the thesis goes
\mainmatter

% Citera med \texttt{} och \parencite{}

\chapter{Introduktion}

Koppla första mening till titel.

söka på speicfika saker i en annons.
mysig inledning.

Deeplearning bildanalys - google grejer.

Ai och hur automatisering vuxit fram. 
Lite fakta på hur viktig sökfunktioner är för att hitta bostäder? Hur många sökningar /tidsenehet

Om folk enklare hittar bostad på ett mer effektivt sätt så effektiviseras hela köp och sälj processen och därmed hela marknaden.


  \section{Problemformulering}
  För att hitta nyckelord kopplade till en bild idag så behöver någon manuellt bestämma nyckelord till bilden. Uppgiften är tidskrävande och det är svårt att i efterhand producera relevanta nyckelord utan att gå igenom allt manuellt igen. 

  Det är också för bostadssökare tidskrävande att leta efter bostäder. Om man kan förfina sökningen än mer skulle detta effektivisera processen.

  Syftet med den här studien är att titta på hur maskininlärningsmetoder kan användas för att hitta relevanta nyckelord till bilder på lägenhetsannonser. 

  \section{Frågeställning}
  Går det med nuvarande verktyg inom maskininlärning hitta attribut i bilder från lägenhetsannonser?


  \section{Avgränsningar}
  Vilka avgränsningar vi gjort i datamängder, testpersoner samt modeller.



\chapter{Bakgrund}
I det här kapitlet presenteras teori som är relevant för bildklassificering.
Målet är att ge läsaren förståelse för de byggstenar som används för att konstruera en modern algoritm för bildklassificering.
De vanligaste verktygen inom modern bildkategorisering bygger på djupinlärning, som är en del inom artificella neurala nätverk.


  \section{Maskininlärning}
  Maskininlärning är ett aktivt forskningsfält inom datalogi och en maskininlärningsalgoritm kan förklaras som en algoritm som lär sig att bli bättre med hjälp utav data \parencite{Goodfellow-et-al-2016}.
  Inom maskininlärning så brukar lärandeprocessen se ut på följande sätt: Om ett datorprogam har som uppgift att med hjälp av en viss erfarenhet E, lära sig vissa förutbestämda uppgifter T, vilket kan mätas med måttet P. Om programmets prestanda P blir bättre, det vill säga att programmet blir bättre på att lösa uppgifterna T, med hjälp av erfarenheten E, då lär sig programmet.

  Maskininlärning brukar delas in i två överkategorier: Unsupervised learning och Supervised learning.
  Det som skiljer dessa åt är att inom supervised learning så är all data redan kategoriserad och uppmärkt för ändamålet medan inom unsupervised learning så är den inte det. Det kan ses som att vi i ena fallet redan har de rätta svaren på vår data. 
  Algoritmer inom unsupervised learning handlar huvudsakligen om att kategorisera data i olika kluster eller på andra sätt försöka förstå den tillgänliga datan. 
  Supervised learning handlar istället om att utgå ifrån den uppmärkta datan och lära sig utav den för att göra samma typ av kategorisering som datan redan är kategoriserad i. 
  Denna funktionsapproximation kan sedan användas för klassificering av ny omärkt data.
  Det finns även andra grenar tillämpningsområden inom supervised learning utöver klassificering.


  \section{Artificella Neurala Nätverk}
  Ett område med många tillämpningsområden inom maskininlärning är artificella neurala nätverk.
  Neurala nätverk var från början ett försök till att bygga en digital modell av hur det biologiska neuronsystem fungerar.
  Forskningen inom områden avvek sedan från att efterlikna den biologiska varianten så mycket som möjligt och fokuserade istället på att konstruera neurala nätverk som fungerade så bra som möjligt på maskininlärningsproblem.
  Grundbyggstenarna i neurala nätverk är dock fortfarande baserade på dess biologiska variant.
  Den enklaste beräkningsenheten i hjärnan är en neuron och dessa neuroner är ihopkopplade med synapser.
  En neuron får signal in och skickar sedan signaler ut via synapserna.
  Hur stark utsignal är simuleras i en dator med hjälp av vikter, (engelska: weights, W).
  Målet är att träna modellen och göra den bättre genom att justera vikterna.
  Om summan av flera av dessa viktade insignaler når en viss gräns, så skickar neuronerna vidare en signal.
  Detta simuleras i en dator med en aktiveringsfunktion.

  Neurala nätverk är dessa neuroner i en acyklisk graf.

  [BILD PÅ NEURALT NÄTVERK]

  Ett vanligt neuralt nätverk består vanligtvis först av ett indatalager (input layer). Indatalagret brukar representeras av en neuron per egenskap i indatan. 
  Då indata är bilder så brukar en neuron i indatalagret motsvara en pixel i en bild.
  Dessa neuroner i indatalagret är sedan ihopkopplade med ett nytt lager med neuroner.
  Detta lager kallas för det gömda lagret (hidden layer).
  De gömda lagren kan bestå av godtyckligt många neuroner.
  Det går att ha en eller fler gömda lager efter varandra och efter det kommer utdatalagret (output layer).
  Utdatalagret består vanligtvis av lika många neuroner som modellen ska ge olika svar.
  Om modellen ska kategorisera indata i tio olika kategorier, så borde modellen då ha tio neuroner i sitt utdatalager.

  Ett neuralt nätverk blir bättre på sin uppgift genom att ändra sina vikter, vilka även kallas för parametrar. Detta sker i två steg. Första steget är feed-forward pass. Feed-forward pass handlar om att skicka in sin träningsdata genom nätverket och få ut ett svar eller klassificering.
  Då träningsdatan redan är uppmärkt så jämfört svaret från det neurala nätverket med det riktiga svaret. Beroende på hur många fel nätverket gissade och hur osäker det var när det gissade fel, så beräknas en kostnad. Det finns olika sätt att beräkna denna kostnad men vanligtvis används cross-entropy loss. Målet med att träna modellen är att få denna kostnad så låg som möjligt. Nästa steg är backward pass, vilket även kallas för backpropagation. Det vi vill göra är att ändra parametrarna så att kostnaden vi beräknade innan blir lägre. Detta görs genom att beräkna gradienten av kostnaden med avseende på alla parametrarna. Vi kan sedan ta ett steg åt motsatt håll som gradienten, för att minska kostnaden. Storleken på detta steg kallas för learning rate.

  \subsection{Stochastic gradient descent}
  Stochastic Gradient Descent heter den vanligaste algoritmen för att uppdatera parametrarna med hjälp av gradienten. Den bygger på samma tvåstegsmodell som beskriven ovan men istället för att beräkna gradienten för alla datapunkter i träningsmängden så väljs några stycken ut som man beräknar gradienten på. Denna delmängd brukar kallas för batch och dess storlek för batch size. En epoch är när modellen har gått igenom alla datapunker i träningsmängden en gång. Learning rate är då hur stort steg åt gradientens motsatta håll vi ändrar på parametrarna vid varje uppdatering.

  [FORMEL PÅ SGD]

  En förbättring till learning rate är the momentum method. Stochastic gradient descent med momentum kommer ihåg förändringen av parametrarna vid varje iteration och baserar nästa uppdatering på en linjärkombination av gradienten och den tidigare förändringen. 

  [FORMEL PÅ MOMENTUM]

  \section{Convolutional Neural Network}
  Convolutional neural networks (CNN) är en viss typ av neurala nätverk för att processera data som har indata som är placerat i ett rutnät. Det inkluderar data om tidsserier men även bilddata, som kan ses som ett rutnät av pixlar. CNN har fått stort genomslagskraft i praktiska tillämpningar. Convolution är en viss typ av linjär operation och CNN är då neurala nätverk där minst ett av dess lager är ett convolutional layer. 

    \subsection{Lager}
    Här presenteras de lager som vanligtvis används i ett CNN. 
    Detta för att sedan kunna gå in på hur de olika arktitekterna inom CNN är uppbyggda.
    Även om CNN kan användas till olika typer av data, så fokuserar vi här i texten på dess kontext med bilder.

      \subsubsection{Input}
      Detta lager håller de råa pixelvärdena från bilden via skickar. 


    \subsection{Tekniker inom djupinlärning}

    \subsection{Arkitekturer}

  \section{Transfer Learning}



\chapter{Metod}
Hur vi gått tillväga. Vilka dataset, hur implementation gått till (verktyg, klassificerare, parametrar), hur vi valt features.
Hur evalueringen har gått till (traning, test, validation set).

Vi vill mäta både precision och recall. Plotta en PR curve.

Vi kan även plotta hur precisionen har gått om i förhållande till mer data, för att skapa en uppfattning av om modellen kan bli bättre med mer data. Vanligtvis gör man detta i log-skala \parencite{Goodfellow-et-al-2016}. 

Gör även att göra en grid search på hyperparametrar.

Hur vi kan använda oss av preprocessing kan vi  läsa i kapitel 12 av Goodfellow.

\chapter{Resultat}
Prestandan av de olika modeller kommer presenteras här.

  \section{Balkonger}
  Här nedan presenteras resultatet av den binära klassificeringen av balkonger i mäklarbilder.
  Resultatet består av två grafer per modell, som visar hur kostnaden från kostnadsfunktionen samt noggrannheten för både vårt träningssset och evalueringsset.
  Det finns även en sammanställning av de högst uppnådda noggrannheten och hur lång tid modellerna tog att träna upp.
  Vi kommer även titta på både när alla lager var frysta och när alla lager tränades.

    \subsection{Feature extractor}
    Detta var när vi bara tränade det sista lagret.

    \begin{figure}
      \centering
      \includegraphics[width=0.49\textwidth]{"./balcony/balcony-20split - acc - resnet - feature extractor"}
      \includegraphics[width=0.49\textwidth]{"./balcony/balcony-20split - loss - resnet - feature extractor"}
      \caption{Arkitekturen ResNet-11}
    \end{figure}

    \begin{figure}
      \centering
      \includegraphics[width=0.49\textwidth]{"./balcony/balcony-20split - acc - alexnet - feature extractor"}
      \includegraphics[width=0.49\textwidth]{"./balcony/balcony-20split - loss - alexnet - feature extractor"}
      \caption{Arkitekturen Alexnet}
    \end{figure}

    \begin{figure}
      \centering
      \includegraphics[width=0.49\textwidth]{"./balcony/balcony-20split - acc - vgg - feature extractor"}
      \includegraphics[width=0.49\textwidth]{"./balcony/balcony-20split - loss - vgg - feature extractor"}
      \caption{Arkitekturen VGG-11 med batch normalization}
    \end{figure}

    \begin{figure}
      \centering
      \includegraphics[width=0.49\textwidth]{"./balcony/balcony-20split - acc - densenet - feature extractor"}
      \includegraphics[width=0.49\textwidth]{"./balcony/balcony-20split - loss - densenet - feature extractor"}
      \caption{Arkitekturen Densenet}
    \end{figure}

    \begin{figure}
      \centering
      \includegraphics[width=0.49\textwidth]{"./balcony/balcony-20split - acc - inception - feature extractor"}
      \includegraphics[width=0.49\textwidth]{"./balcony/balcony-20split - loss - inception - feature extractor"}
      \caption{Arkitekturen Inception V3}
    \end{figure}

    \begin{table}
      \centering
      \begin{tabular}{|l|r|r|}
        Modell & Tid & Max. noggrannhet \\ 
        \hline
        Resnet       & 3m 37s & 94.63 \\
        Alexnet      & 3m 18s & 94.27 \\
        VGG-11       & 6m 21s & 93.86 \\
        Densenet     & 5m 59s & 96.94 \\
        Inception V3 & 9m 04s & 95.80 \\
      \end{tabular}
      \caption{Sammanställning av feature extraction} \label{tab:sometab}
    \end{table}

    \subsection{Finetuning}
    Detta var när vi bara tränade alla lager.

    \begin{figure}
      \centering
      \includegraphics[width=0.49\textwidth]{"./balcony/balcony-20split - acc - resnet - finetuning"}
      \includegraphics[width=0.49\textwidth]{"./balcony/balcony-20split - loss - resnet - finetuning"}
      \caption{Arkitekturen ResNet-11}
    \end{figure}

    \begin{figure}
      \centering
      \includegraphics[width=0.49\textwidth]{"./balcony/balcony-20split - acc - alexnet - finetuning"}
      \includegraphics[width=0.49\textwidth]{"./balcony/balcony-20split - loss - alexnet - finetuning"}
      \caption{Arkitekturen Alexnet}
    \end{figure}

    \begin{figure}
      \centering
      \includegraphics[width=0.49\textwidth]{"./balcony/balcony-20split - acc - vgg - finetuning"}
      \includegraphics[width=0.49\textwidth]{"./balcony/balcony-20split - loss - vgg - finetuning"}
      \caption{Arkitekturen VGG-11 med batch normalization}
    \end{figure}

    \begin{figure}
      \centering
      \includegraphics[width=0.49\textwidth]{"./balcony/balcony-20split - acc - densenet - finetuning"}
      \includegraphics[width=0.49\textwidth]{"./balcony/balcony-20split - loss - densenet - finetuning"}
      \caption{Arkitekturen Densenet}
    \end{figure}

    \begin{figure}
      \centering
      \includegraphics[width=0.49\textwidth]{"./balcony/balcony-20split - acc - inception - finetuning"}
      \includegraphics[width=0.49\textwidth]{"./balcony/balcony-20split - loss - inception - finetuning"}
      \caption{Arkitekturen Inception V3}
    \end{figure}

    Här nedan är sammanställningen av modellerna för finetuning.

    \begin{table}
      \centering
      \begin{tabular}{|l|r|r|}
        Modell & Tid & Max. noggrannhet \\ 
        \hline
        Resnet       & 06m 06s & 96.56 \\
        Alexnet      & 03m 37s & 95.41 \\
        VGG-11       & 15m 55s & 97.32 \\
        Densenet     & 13m 55s & 97.70 \\
        Inception V3 & 21m 54s & 98.09 \\
      \end{tabular}
      \caption{Sammanställning av finetuning} \label{tab:sometab}
    \end{table}
  

  \section{Eldstäder}
  Här nedan presenteras resultatet av bilderna med eldstäder.

  \subsection{Feature extractor}
  Detta var när vi bara tränade det sista lagret med eldstäder.

  \begin{figure}
    \centering
    \includegraphics[width=0.49\textwidth]{"./fireplace/fireplace-classification - acc - resnet - feature extractor"}
    \includegraphics[width=0.49\textwidth]{"./fireplace/fireplace-classification - loss - resnet - feature extractor"}
    \caption{Arkitekturen ResNet-11}
  \end{figure}

  \begin{figure}
    \centering
    \includegraphics[width=0.49\textwidth]{"./fireplace/fireplace-classification - acc - alexnet - feature extractor"}
    \includegraphics[width=0.49\textwidth]{"./fireplace/fireplace-classification - loss - alexnet - feature extractor"}
    \caption{Arkitekturen Alexnet}
  \end{figure}

  \begin{figure}
    \centering
    \includegraphics[width=0.49\textwidth]{"./fireplace/fireplace-classification - acc - vgg - feature extractor"}
    \includegraphics[width=0.49\textwidth]{"./fireplace/fireplace-classification - loss - vgg - feature extractor"}
    \caption{Arkitekturen VGG-11 med batch normalization}
  \end{figure}

  \begin{figure}
    \centering
    \includegraphics[width=0.49\textwidth]{"./fireplace/fireplace-classification - acc - densenet - feature extractor"}
    \includegraphics[width=0.49\textwidth]{"./fireplace/fireplace-classification - loss - densenet - feature extractor"}
    \caption{Arkitekturen Densenet}
  \end{figure}

  \begin{figure}
    \centering
    \includegraphics[width=0.49\textwidth]{"./fireplace/fireplace-classification - acc - inception - feature extractor"}
    \includegraphics[width=0.49\textwidth]{"./fireplace/fireplace-classification - loss - inception - feature extractor"}
    \caption{Arkitekturen Inception V3}
  \end{figure}

  \begin{table}
    \centering
    \begin{tabular}{|l|r|r|}
      Modell & Tid & Max. noggrannhet \\ 
      \hline
      Resnet       & 02m 06s & 80.50 \\
      Alexnet      & 01m 55s & 80.50 \\
      VGG-11       & 03m 45s & 77.35 \\
      Densenet     & 03m 35s & 73.58 \\
      Inception V3 & 05m 15s & 79.24 \\
    \end{tabular}
    \caption{Sammanställning av feature extraction} \label{tab:sometab}
  \end{table}

  \subsection{Finetuning}
  Detta var när vi bara tränade alla lager för eldstäder.

  \begin{figure}
    \centering
    \includegraphics[width=0.49\textwidth]{"./fireplace/fireplace-classification - acc - resnet - finetuning"}
    \includegraphics[width=0.49\textwidth]{"./fireplace/fireplace-classification - loss - resnet - finetuning"}
    \caption{Arkitekturen ResNet-11}
  \end{figure}

  \begin{figure}
    \centering
    \includegraphics[width=0.49\textwidth]{"./fireplace/fireplace-classification - acc - alexnet - finetuning"}
    \includegraphics[width=0.49\textwidth]{"./fireplace/fireplace-classification - loss - alexnet - finetuning"}
    \caption{Arkitekturen Alexnet}
  \end{figure}

  \begin{figure}
    \centering
    \includegraphics[width=0.49\textwidth]{"./fireplace/fireplace-classification - acc - vgg - finetuning"}
    \includegraphics[width=0.49\textwidth]{"./fireplace/fireplace-classification - loss - vgg - finetuning"}
    \caption{Arkitekturen VGG-11 med batch normalization}
  \end{figure}

  \begin{figure}
    \centering
    \includegraphics[width=0.49\textwidth]{"./fireplace/fireplace-classification - acc - densenet - finetuning"}
    \includegraphics[width=0.49\textwidth]{"./fireplace/fireplace-classification - loss - densenet - finetuning"}
    \caption{Arkitekturen Densenet}
  \end{figure}

  \begin{figure}
    \centering
    \includegraphics[width=0.49\textwidth]{"./fireplace/fireplace-classification - acc - inception - finetuning"}
    \includegraphics[width=0.49\textwidth]{"./fireplace/fireplace-classification - loss - inception - finetuning"}
    \caption{Arkitekturen Inception V3}
  \end{figure}

  Här nedan är sammanställningen av modellerna för finetuning.

  \begin{table}
    \centering
    \begin{tabular}{|l|r|r|}
      Modell & Tid & Max. noggrannhet \\ 
      \hline
      Resnet       & 03m 31s & 79.24 \\
      Alexnet      & 02m 08s & 77.35 \\
      VGG-11       & 08m 56s & 81.13 \\
      Densenet     & 07m 55s & 85.53 \\
      Inception V3 & 12m 54s & 83.64 \\
    \end{tabular}
    \caption{Sammanställning av finetuning} \label{tab:sometab}
  \end{table}



  \section{Rum}
  Resultat från olika rum.


\chapter{Diskussion}
Diskutera resultatet och hur olika delar kan ha påverkat eller påverkade. Diskutera eventuell framtida forskning. Begränsningar med resultatet.
Etiska aspekter. Hållbarhet. 

  \section{Fortsätt forskning}
  Vid värdering så är det också intressant att få ut attribut, så kan man räkna med det i värderingskalkylen.

\chapter{Slutsats}
Slutsats av vad vi kom fram till.

\printbibliography[heading=bibintoc]
\appendix
  \chapter{Appendix A}

\tailmatter
\end{document}
