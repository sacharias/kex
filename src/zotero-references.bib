
@misc{um_most_2019,
	title = {The most cited deep learning papers. {Contribute} to terryum/awesome-deep-learning-papers development by creating an account on {GitHub}},
	url = {https://github.com/terryum/awesome-deep-learning-papers},
	urldate = {2019-03-22},
	author = {Um, Terry Taewoong},
	month = mar,
	year = {2019},
	note = {original-date: 2016-06-03T06:48:30Z}
}

@inproceedings{ayers_home_2007,
	title = {Home {Interior} {Classification} using {SIFT} {Keypoint} {Histograms}},
	doi = {10.1109/CVPR.2007.383485},
	abstract = {Semantic scene classification, the process of categorizing photographs into a discrete set of classes using pattern recognition techniques, is a useful ability for image annotation, organization and retrieval. The literature has focused on classifying outdoor scenes such as beaches and sunsets. Here, we focus on a much more difficult problem, that of differentiating between typical rooms in home interiors, such as bedrooms or kitchens. This requires robust image feature extraction and classification techniques, such as SIFT (scale-invariant feature transform) features and Adaboost classifiers. To this end, we derived SIFT keypoint histograms, an efficient image representation that utilizes variance information from linear discriminant analysis. We compare SIFT keypoint histograms with other features such as spatial color moments and compare Adaboost with support vector machine classifiers. We outline the various techniques used, show their advantages, disadvantages, and actual performance, and determine the most effective algorithm of those tested for home interior classification. Furthermore, we present results of pairwise classification of 7 rooms typically found in homes.},
	booktitle = {2007 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Ayers, B. and Boutell, M.},
	month = jun,
	year = {2007},
	keywords = {categorizing photographs, feature extraction, Feature extraction, Histograms, home interior classification, image annotation, image classification, image feature extraction, image organization, Image representation, image retrieval, Image retrieval, Layout, linear discriminant analysis, Linear discriminant analysis, pattern recognition, Pattern recognition, Robustness, scale-invariant feature transform, semantic scene classification, SIFT keypoint histograms, support vector machine classification, Support vector machine classification, support vector machines, Support vector machines},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:/Users/sacharias/Zotero/storage/3AW4Y7NV/4270483.html:text/html;IEEE Xplore Full Text PDF:/Users/sacharias/Zotero/storage/SFV7W9PK/Ayers and Boutell - 2007 - Home Interior Classification using SIFT Keypoint H.pdf:application/pdf}
}

@incollection{krizhevsky_imagenet_2012,
	title = {{ImageNet} {Classification} with {Deep} {Convolutional} {Neural} {Networks}},
	url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
	urldate = {2019-03-22},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 25},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	year = {2012},
	pages = {1097--1105},
	file = {NIPS Snapshot:/Users/sacharias/Zotero/storage/N8Q547NT/4824-imagenet-classification-with-deep-convolutional-neural-networ.html:text/html}
}

@article{howard_mobilenets:_2017,
	title = {{MobileNets}: {Efficient} {Convolutional} {Neural} {Networks} for {Mobile} {Vision} {Applications}},
	shorttitle = {{MobileNets}},
	url = {http://arxiv.org/abs/1704.04861},
	abstract = {We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization.},
	urldate = {2019-03-22},
	journal = {arXiv:1704.04861 [cs]},
	author = {Howard, Andrew G. and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
	month = apr,
	year = {2017},
	note = {arXiv: 1704.04861},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1704.04861 PDF:/Users/sacharias/Zotero/storage/GK3G3Y5Z/Howard et al. - 2017 - MobileNets Efficient Convolutional Neural Network.pdf:application/pdf;arXiv.org Snapshot:/Users/sacharias/Zotero/storage/IFSTMSJT/1704.html:text/html}
}

@inproceedings{oquab_learning_2014,
	title = {Learning and {Transferring} {Mid}-{Level} {Image} {Representations} using {Convolutional} {Neural} {Networks}},
	url = {http://openaccess.thecvf.com/content_cvpr_2014/html/Oquab_Learning_and_Transferring_2014_CVPR_paper.html},
	urldate = {2019-03-22},
	author = {Oquab, Maxime and Bottou, Leon and Laptev, Ivan and Sivic, Josef},
	year = {2014},
	pages = {1717--1724},
	file = {Full Text PDF:/Users/sacharias/Zotero/storage/IS9CJK8Z/Oquab et al. - 2014 - Learning and Transferring Mid-Level Image Represen.pdf:application/pdf;Snapshot:/Users/sacharias/Zotero/storage/BV6XWUUV/Oquab_Learning_and_Transferring_2014_CVPR_paper.html:text/html}
}