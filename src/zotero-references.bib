
@article{ioffe_batch_2015,
	title = {Batch {Normalization}: {Accelerating} {Deep} {Network} {Training} by {Reducing} {Internal} {Covariate} {Shift}},
	shorttitle = {Batch {Normalization}},
	url = {http://arxiv.org/abs/1502.03167},
	abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.},
	urldate = {2019-03-22},
	journal = {arXiv:1502.03167 [cs]},
	author = {Ioffe, Sergey and Szegedy, Christian},
	month = feb,
	year = {2015},
	note = {arXiv: 1502.03167},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv\:1502.03167 PDF:/Users/sacharias/Zotero/storage/SUMXANIT/Ioffe and Szegedy - 2015 - Batch Normalization Accelerating Deep Network Tra.pdf:application/pdf;arXiv.org Snapshot:/Users/sacharias/Zotero/storage/FGC3JKSS/1502.html:text/html}
}

@article{razavian_cnn_2014,
	title = {{CNN} {Features} off-the-shelf: an {Astounding} {Baseline} for {Recognition}},
	shorttitle = {{CNN} {Features} off-the-shelf},
	url = {http://arxiv.org/abs/1403.6382},
	abstract = {Recent results indicate that the generic descriptors extracted from the convolutional neural networks are very powerful. This paper adds to the mounting evidence that this is indeed the case. We report on a series of experiments conducted for different recognition tasks using the publicly available code and model of the {\textbackslash}overfeat network which was trained to perform object classification on ILSVRC13. We use features extracted from the {\textbackslash}overfeat network as a generic image representation to tackle the diverse range of recognition tasks of object image classification, scene recognition, fine grained recognition, attribute detection and image retrieval applied to a diverse set of datasets. We selected these tasks and datasets as they gradually move further away from the original task and data the {\textbackslash}overfeat network was trained to solve. Astonishingly, we report consistent superior results compared to the highly tuned state-of-the-art systems in all the visual classification tasks on various datasets. For instance retrieval it consistently outperforms low memory footprint methods except for sculptures dataset. The results are achieved using a linear SVM classifier (or \$L2\$ distance in case of retrieval) applied to a feature representation of size 4096 extracted from a layer in the net. The representations are further modified using simple augmentation techniques e.g. jittering. The results strongly suggest that features obtained from deep learning with convolutional nets should be the primary candidate in most visual recognition tasks.},
	urldate = {2019-03-25},
	journal = {arXiv:1403.6382 [cs]},
	author = {Razavian, Ali Sharif and Azizpour, Hossein and Sullivan, Josephine and Carlsson, Stefan},
	month = mar,
	year = {2014},
	note = {arXiv: 1403.6382},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: version 3 revisions: 1)Added results using feature processing and data augmentation 2)Referring to most recent efforts of using CNN for different visual recognition tasks 3) updated text/caption},
	file = {arXiv\:1403.6382 PDF:/Users/sacharias/Zotero/storage/LBVYVM7C/Razavian et al. - 2014 - CNN Features off-the-shelf an Astounding Baseline.pdf:application/pdf;arXiv.org Snapshot:/Users/sacharias/Zotero/storage/G8J8YX7J/1403.html:text/html}
}

@article{he_deep_2015,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	url = {http://arxiv.org/abs/1512.03385},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	urldate = {2019-04-28},
	journal = {arXiv:1512.03385 [cs]},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = dec,
	year = {2015},
	note = {arXiv: 1512.03385},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Tech report},
	file = {arXiv\:1512.03385 PDF:/Users/sacharias/Zotero/storage/ETFULNGE/He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf:application/pdf;arXiv.org Snapshot:/Users/sacharias/Zotero/storage/PZRX4VEI/1512.html:text/html}
}